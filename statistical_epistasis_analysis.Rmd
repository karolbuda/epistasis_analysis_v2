---
title: "statistical_analysis_epistasis"
output: html_document
---

```{r, setup, include=FALSE}
knitr::opts_knit$set(root.dir = "/Users/karolbuda/OneDrive - UBC/PhD/Epistasis_Lit/Bulk/Output")

library(tidyverse)
library(ggExtra)
library(ggrepel)
```

## Fold-Change Data

Here we look at the fold-change data used in the input files. This allows us to see positive and negative functional effects across the landscapes.

```{r, message=F}
fit_land = do.call("rbind", lapply(list.files(pattern="observed_values.csv", recursive = T), read_csv, skip = 1, show_col_types=F, col_names = c("id", "effect", "muts", "2", "3", "enz"))) %>% select(-c('2', '3'))
```

The data shows the following distribution

```{r}
c(sum(fit_land$effect < log10(1/1.5)), sum(fit_land$effect >= log10(1/1.5) & fit_land$effect <= log10(1.5)), sum(fit_land$effect > log10(1.5)))
```

### Histogram

```{r}
fit_land %>%
  ggplot(aes(x = effect, fill = enz)) +
  geom_histogram(bins = 100, alpha = 0.8) +
  geom_vline(xintercept = log10(1.5), lty = 2) +
  geom_vline(xintercept = log10(1/1.5), lty = 2) +
  theme_classic() +
  theme(text = element_text(size=18), axis.text = element_text(size = 16, color = "black"),
        axis.title.y = element_blank(),
        axis.title.x = element_blank())
```

## Ratio Data

First we import the ratio datasets, which contains ratio values between predicted function based on the additive model vs observed function. These ratio values serve as a general metric for epistasis.

```{r, message = F}

all_ratios = do.call("rbind", lapply(list.files(pattern="ratio_export.csv", recursive = T), read_csv, skip = 1, show_col_types=F, col_names = c("id", "effect", "muts", "cv", "colors")))

```

Filtering ratio data to only include genotypes with 2+ mutations. Outputting length of vector.

```{r}
all_ratios = all_ratios %>% filter(muts > 1)

length(all_ratios$effect) # examined muts
```

Number and % of synergystic genotypes (i.e. ratio > 1.5-fold)

```{r}
sum(all_ratios$effect > 1.5) # synergystic
paste0("Synergystic ", round(sum(all_ratios$effect > 1.5)/length(all_ratios$effect)*100,2), "%", collapse = "") # synergystic %
```

Number and % of neutral genotypes (i.e. ratio > 1.5-fold)

```{r}
sum(all_ratios$effect >= 1/1.5 & all_ratios$effect <= 1.5) # antagonistic
paste0("Neutral ", round(sum(all_ratios$effect >= 1/1.5 & all_ratios$effect <= 1.5)/length(all_ratios$effect)*100, 2), "%", collapse = "") # antagonistic %
```

Number and % of antagonistic genotypes (i.e. ratio > 1.5-fold)

```{r}
sum(all_ratios$effect < 1/1.5) # antagonistic
paste0("Antagonistic ", round(sum(all_ratios$effect < 1/1.5)/length(all_ratios$effect)*100, 2), "%", collapse = "") # antagonistic %
```

### Histogram

Shows distribution of positive and negative epistasis across the landscapes 

```{r}
all_ratios %>%
  ggplot(aes(x = log10(effect))) +
  geom_histogram(bins = 100, alpha = 0.8) +
  geom_vline(xintercept = log10(1.5), lty = 2) +
  geom_vline(xintercept = log10(1/1.5), lty = 2) +
  theme_classic() +
  theme(text = element_text(size=18), axis.text = element_text(size = 16, color = "black"),
        axis.title.y = element_blank(),
        axis.title.x = element_blank())
```

We can do the same thing for 2nd, 3rd, and 4th order

### 2nd order
```{r}
## 2nd step only

all_ratios_2 = all_ratios %>% filter(muts == 2)

length(all_ratios_2$effect) # examined muts

sum(all_ratios_2$effect > 1.5) # synergystic
paste0("Synergystic ", round(sum(all_ratios_2$effect > 1.5)/length(all_ratios_2$effect)*100, 2), "%", collapse = "") # synergystic %

sum(all_ratios_2$effect >= 1/1.5 & all_ratios_2$effect <= 1.5) # antagonistic
paste0("Neutral ", round(sum(all_ratios_2$effect >= 1/1.5 & all_ratios_2$effect <= 1.5)/length(all_ratios_2$effect)*100, 2), "%", collapse = "") # antagonistic %

sum(all_ratios_2$effect < 1/1.5) # antagonistic
paste0("Antagonistic ", round(sum(all_ratios_2$effect < 1/1.5)/length(all_ratios_2$effect)*100, 2), "%", collapse = "") # antagonistic %
```
### 3rd order
```{r}
## 3rd step only

all_ratios_3 = all_ratios %>% filter(muts == 3)

length(all_ratios_3$effect) # examined muts

sum(all_ratios_3$effect > 1.5) # synergystic
paste0("Synergystic ", round(sum(all_ratios_3$effect > 1.5)/length(all_ratios_3$effect)*100, 2), "%", collapse = "") # synergystic %

sum(all_ratios_3$effect >= 1/1.5 & all_ratios_3$effect <= 1.5) # antagonistic
paste0("Neutral ", round(sum(all_ratios_3$effect >= 1/1.5 & all_ratios_3$effect <= 1.5)/length(all_ratios_3$effect)*100, 2), "%", collapse = "") # antagonistic %

sum(all_ratios_3$effect < 1/1.5) # antagonistic
paste0("Antagonistic ", round(sum(all_ratios_3$effect < 1/1.5)/length(all_ratios_3$effect)*100, 2), "%", collapse = "") # antagonistic %
```
### 4th order
```{r}
## 4th step only

all_ratios_4 = all_ratios %>% filter(muts == 4)

length(all_ratios_4$effect) # examined muts

sum(all_ratios_4$effect > 1.5) # synergystic
paste0("Synergystic ", round(sum(all_ratios_4$effect > 1.5)/length(all_ratios_4$effect)*100, 2), "%", collapse = "") # synergystic %

sum(all_ratios_4$effect >= 1/1.5 & all_ratios_4$effect <= 1.5) # antagonistic
paste0("Neutral ", round(sum(all_ratios_4$effect >= 1/1.5 & all_ratios_4$effect <= 1.5)/length(all_ratios_4$effect)*100, 2), "%", collapse = "") # antagonistic %

sum(all_ratios_4$effect < 1/1.5) # antagonistic
paste0("Antagonistic ", round(sum(all_ratios_4$effect < 1/1.5)/length(all_ratios_4$effect)*100, 2), "%", collapse = "") # antagonistic %
```

## Positional Functional Contribution Data

Here we import the functional contribution of single positions (not combinations), which resembles first order analysis across all datasets.

```{r,message=F}
## Reads all csvs in collated folder and combines them

d = do.call("rbind", lapply(list.files(pattern="*2d_box.csv", recursive = T), read_csv, show_col_types=F, col_names = c("positions", "identity", "mut", "effects", "enzyme", "type", "cond")))


d1 = d %>% filter_all(any_vars(!is.na(.))) # removes rows with all NA before making unique ID

d1 = d1 %>%
  unite("unique_id", c(positions, enzyme, type, cond), remove = F)
```

### Histogram

Spread of functional contributions of the positions. This shows whether introducing a mutation in a given position impacts the function positively or negatively (or neutral)

```{r}
d1 %>%
  ggplot(aes(x = effects, fill = enzyme)) +
  geom_histogram(bins = 100, alpha = 0.8) +
  geom_vline(xintercept = log10(1.5), lty = 2) +
  geom_vline(xintercept = log10(1/1.5), lty = 2) +
  theme_classic() +
  theme(text = element_text(size=18), axis.text = element_text(size = 16, color = "black"),
        axis.title.y = element_blank(),
        axis.title.x = element_blank())
```

Given this spread which percentage is significantly (using log10 1.5-fold cutoff) **negative**, **neutral**, and **positive** in that order

```{r}

general = c(sum(d1$effects < log10(1/1.5)) / length(d1$effects),
  sum(d1$effects <= log10(1.5) & d1$effects >= log10(1/1.5)) / length(d1$effects),
  sum(d1$effects > log10(1.5)) / length(d1$effects)
)

general
```

## Heterogenity in Spread

Looks at 2*SD of each position/combination across all orders to determine functional heterogeneity.

This gives us a quick look at the general spread of heterogenity values and their mean.

```{r,message=F}

idio_d = do.call("rbind", lapply(list.files(pattern="idio_df", recursive = T), read_csv, show_col_types=F))

idio_d %>%
  ggplot(aes(x = mutations, y = idiosync)) +
  geom_point() +
  geom_hline(yintercept = 0) +
  geom_hline(yintercept = log10(1.5), lty = 2) +
  stat_summary(fun=mean, colour="black", geom="crossbar", width=0.2) +
  labs(x = "Order", y = "Heterogenity Index") +
  theme_classic()
```
### Order 1

```{r}
idio_d %>%
  filter(mutations == "Order 1") %>%
  ggplot(aes(x = idiosync)) +
  geom_histogram(binwidth = 0.1, fill = "#edae49") +
  geom_vline(xintercept = log10(1.5), lty = 2, lwd = 1) +
  geom_vline(xintercept = log10(2), lty = 2, lwd = 1) +
  geom_vline(xintercept = log10(5), lty = 2, lwd = 1) +
  geom_vline(xintercept = log10(10), lty = 2, lwd = 1) +
  labs(x = "Heterogenity Index",
       y = "Genotype Count") +
  theme_classic() +
  theme(text = element_text(size=18), axis.text = element_text(size = 16),
        axis.title.y = element_text(margin = margin(t = 0, r = 20, b = 0, l = 0)),
        axis.title.x = element_text(margin = margin(t = 20, r = 0, b = 0, l = 0)))

```
First order positions which have a hetergenity index > log10 1.5-fold, 2-fold, 5-fold, and 10-fold 

```{r}
idio_first = idio_d %>% 
  filter(mutations == "Order 1") %>%
  pull(idiosync)

sum(idio_first > log10(1.5)) / length(idio_first)
sum(idio_first > log10(2)) / length(idio_first)
sum(idio_first > log10(5)) / length(idio_first)
sum(idio_first > log10(10)) / length(idio_first)
```
### Order 2-4

Histogram to show heterogenity at Orders 2, 3, and 4 with the log10 1.5-fold significance threshold

```{r}
idio_d %>%
  filter(mutations == "Order 2" | mutations == "Order 3" | mutations == "Order 4") %>%
  ggplot(aes(x = idiosync)) +
  geom_histogram(binwidth = 0.1, fill = "#edae49") +
  geom_vline(xintercept = log10(1.5), lty = 2, lwd = 1) +
  labs(x = "Idiosyncrasy Metric",
       y = "Genotype Count") +
  facet_wrap(~ mutations) +
  theme_classic() +
  theme(text = element_text(size=18), axis.text = element_text(size = 16, color = "black"),
        axis.title.y = element_blank(),
        axis.title.x = element_blank(),
        legend.position = "none",
        strip.background = element_blank(),
        strip.text.x = element_blank())
```

What percentage of positions remain significantly heterogeneous at these orders?

```{r}
idio_d %>%
  filter(mutations == "Order 2" | mutations == "Order 3" | mutations == "Order 4") %>%
  mutate(idiosync = idiosync > log10(1.5)) %>%
  group_by(mutations) %>%
  summarise(idiosync_sig = sum(idiosync),
            idiosync_total = length(idiosync),
            idiosync = sum(idiosync)/length(idiosync) * 100
            )
```

## Heterogenity in Sign

Collects all $\Delta$$\Delta$Function data for all orders

```{r,message=F}
higher_order_list = list.files(pattern="higher_box", recursive = T)

higher_df = data.frame()
for(higher_file in 1:length(higher_order_list)){
  Condition = str_split(str_split(higher_order_list[higher_file], "_")[[1]][3], "/")[[1]][1]
  Measurement = str_split(higher_order_list[higher_file], "_")[[1]][2]
  Enzyme = str_split(higher_order_list[higher_file], "_")[[1]][1]
  appending_file = read_csv(higher_order_list[higher_file], show_col_types=F)
  appending_file$Condition = Condition
  appending_file$Measurement = Measurement
  appending_file$Enzyme = Enzyme
  higher_df = bind_rows(higher_df, appending_file)
}


higher_df = higher_df %>%
  unite("unique_id", c(pos, Condition, Measurement, Enzyme), remove = F)

higher_all_sign_check = higher_df %>%
  mutate(mutations = factor(paste("Order", mutations, sep = " "))) %>%
  group_by(unique_id, mutations) %>%
  summarise(min_effect = min(avg),
            max_effect = max(avg))

```

Assigning positive, neutral, negative, negative-neutral, positive-neutral, and negative-positive 'types' based on log10 1.5-fold threshold to every Order

```{r}

threshold = 1.5

types = c()
for(each in 1:dim(higher_all_sign_check)[1]){
  if(higher_all_sign_check$min_effect[each] < log10(1/threshold)){
    # Negative branch
    if(higher_all_sign_check$max_effect[each] < log10(1/threshold)) {
      # Full negative
      types = c(types, "Negative")
    } else if(higher_all_sign_check$max_effect[each] <= log10(threshold)) {
      # Negative Neutral
      types = c(types, "Neutral Negative")
    } else {
      # Negative Positive
      types = c(types, "Positive Negative")
    }
  } else {
    # Neutral or Positive
    if(higher_all_sign_check$min_effect[each] > log10(threshold)) {
      # Full positive
      types = c(types, "Positive")
    } else if(higher_all_sign_check$max_effect[each] > log10(threshold)) {
      # Neutral Positive
      types = c(types, "Neutral Positive")
    } else {
      # Neutral
      types = c(types, "Neutral")
    }
  }
}

higher_all_sign_check$type = factor(types)
```

All outputs show position/combination numbers in each catagory, followed by the total sum of all probed positions/combinations at that order, and finally percentages of each category


### Order 1

```{r}
order_checker = higher_all_sign_check %>% 
  filter(mutations == "Order 1") %>%
  pull(type) 

summary(order_checker) 
sum(summary(order_checker)) 
summary(order_checker) / length(order_checker) * 100
```

### Order 2

```{r}
order_checker = higher_all_sign_check %>% 
  filter(mutations == "Order 2") %>%
  pull(type) 

summary(order_checker) 
sum(summary(order_checker)) 
summary(order_checker) / length(order_checker) * 100
```

### Order 3

```{r}
order_checker = higher_all_sign_check %>% 
  filter(mutations == "Order 3") %>%
  pull(type) 

summary(order_checker) 
sum(summary(order_checker)) 
summary(order_checker) / length(order_checker) * 100
```

### Order 4

```{r}
order_checker = higher_all_sign_check %>% 
  filter(mutations == "Order 4") %>%
  pull(type) 

summary(order_checker) 
sum(summary(order_checker)) 
summary(order_checker) / length(order_checker) * 100
```

## WT points to Mean Deviation

Purpose of this analysis was to determine the difference in $\Delta$$\Delta$Function between the WT-background contribution of a given position/combination and the mean contribution of a given position or combination

# Histogram

The spread of all positional contribution vs mean differences for each Order (1-4)


```{r,message=F}
higher_df_mean = higher_df %>%
  filter(mutations < 5) %>%
  group_by(unique_id) %>%
  summarise(avg = mean(avg))

devs = c()
cur_mutations = c()
for(i in 1:dim(higher_df_mean)[1]) {
  curr_id = higher_df_mean[i,1] %>% pull(unique_id)
  devs = c(devs, abs( (higher_df %>% filter(!str_detect(genotype, "1")) %>% filter(unique_id == curr_id) %>% pull(avg)) - (higher_df_mean[i,2] %>% pull(avg)) ))
  cur_mutations = c(cur_mutations, (higher_df %>% filter(!str_detect(genotype, "1")) %>% filter(unique_id == curr_id) %>% pull(mutations)))
}

devs_df = data.frame(devs = devs, muts = cur_mutations)

## WT heterogenity for higher_orders

devs_df %>%
  ggplot(aes(x = devs)) +
  geom_histogram(binwidth=0.1, fill = "#edae49") +
  geom_vline(xintercept = log10(1.5), lty = 2, lwd = 1) +
  facet_wrap(~ muts) +
  theme_classic() +
  theme(text = element_text(size=18), axis.text = element_text(size = 16, color = "black"),
        axis.title.y = element_blank(),
        axis.title.x = element_blank(),
        legend.position = "none")
```

Table to show percentages of WT-bg points that deviate from the positional/combinatorial mean by significance threshold (log10 1.5-fold) 

```{r}
devs_df %>%
  mutate(muts = factor(muts)) %>%
  group_by(muts) %>%
  summarise(percent = sum(devs > log10(1.5)) / length(devs),
            outlier = sum(devs > log10(1.5)),
            total = length(devs))

```

## All points to Mean Deviation

Purpose of this analysis was to determine the difference in $\Delta$$\Delta$Function between functional contribution of a given position/combination in any background and the mean contribution of a given position or combination

# Histogram

The spread of all positional contribution vs mean differences for each Order (1-4)


```{r,message=F}
higher_df_mean = higher_df %>%
  filter(mutations < 5) %>%
  group_by(unique_id) %>%
  summarise(avg = mean(avg))

devs = c()
cur_mutations = c()
for(i in 1:dim(higher_df_mean)[1]) {
  curr_id = higher_df_mean[i,1] %>% pull(unique_id)
  devs = c(devs, abs( (higher_df %>% filter(unique_id == curr_id) %>% pull(avg)) - (higher_df_mean[i,2] %>% pull(avg)) ))
  cur_mutations = c(cur_mutations, (higher_df %>% filter(unique_id == curr_id) %>% pull(mutations)))
}

devs_df = data.frame(devs = devs, muts = cur_mutations)

## All heterogenity for higher_orders

devs_df %>%
  ggplot(aes(x = devs)) +
  geom_histogram(binwidth=0.1, fill = "#edae49") +
  geom_vline(xintercept = log10(1.5), lty = 2, lwd = 1) +
  facet_wrap(~ muts) +
  theme_classic() +
  theme(text = element_text(size=18), axis.text = element_text(size = 16, color = "black"),
        axis.title.y = element_blank(),
        axis.title.x = element_blank(),
        legend.position = "none")
```

Table to show percentages of WT-bg points that deviate from the positional/combinatorial mean by significance threshold (log10 1.5-fold) 

```{r}
devs_df %>%
  mutate(muts = factor(muts)) %>%
  group_by(muts) %>%
  summarise(percent = sum(devs > log10(1.5)) / length(devs),
            outlier = sum(devs > log10(1.5)),
            total = length(devs))

```


# Individual Trends

This sections attempts to probe if the previous values from the statistical analysis are representative in the individual data sets

### Sign Heterogenity in Invididual datasets

```{r, message=F}
d_individual = d %>% filter_all(any_vars(!is.na(.))) # removes rows with all NA before making unique ID

d_individual = d_individual %>%
  unite("landscape_id", c(enzyme, type, cond), remove = F)

landscape_ids = unique(d_individual$landscape_id)

general_df = tibble()
for(i in 1:length(landscape_ids)) {
  d_curr_individual = d_individual %>% filter(landscape_id == landscape_ids[i])

  general = c(unique(d_curr_individual$enzyme),
    landscape_ids[i],
    sum(d_curr_individual$effects < log10(1/1.5)) / length(d_curr_individual$effects),
    sum(d_curr_individual$effects <= log10(1.5) & d_curr_individual$effects >= log10(1/1.5)) / length(d_curr_individual$effects),
    sum(d_curr_individual$effects > log10(1.5)) / length(d_curr_individual$effects)
  )

  general_df = rbind(general_df, general)
}
 
colnames(general_df) = c("Enzyme", "Landscape ID", "Negative", "Neutral", "Positive")

general_df[-1]

```

The trend appears to be heterogenous, i.e. the fraction of negative, neutral, and positive is varied across all landscapes but averages out to roughly equal proportions when all landscapes are considered together.

For example, AP shows very negative contribution at 77.5% of all mutations, DHFR kcats are predominantly negative while Kis are almost all positive (due to the adaptive nature of the mutations). MPH shows strong positives as it is also adaptive. NfsA is predominantly neutral, with some positive contribution. OXA is positive and neutral for adaptive trajectories, and negative and neutral for trade-off. PTE is positive for its adaptive substrate, but shows more negative behavior for lactones and OPs. TEM across all antibiotics is predominantly neutral (no directy adaptation). Finally the adaptive MIC of TEM is mostly positive with 66.3%.

```{r}
general_df %>%
  pivot_longer(c(3,4,5)) %>%
  mutate(value = as.numeric(value)*100) %>%
  ggplot(aes(x = name, y = value, color = Enzyme)) +
  geom_point() +
  stat_summary(fun=mean, colour="darkred", geom="crossbar", width=0.2) +
  theme_classic()
```

---

### Still need to implement individual representation of functional heterogeneity and deviation from WT

---

# Prediction

Leaving this section for the MAE prediction part



---

# Trajectory 

### Seeing how adaptive trajectories are affected by epistasis

First I need to create a global trajectory data frame

```{r,message=F}
all_traj = do.call("rbind", lapply(list.files(pattern="traj_epi_*", recursive = T), read_csv, skip = 1, col_names = c("genotype", "avg", "pos", "mutations", "likely", "enzyme_name", "measure_type", "cond")))

all_traj = all_traj %>% unite("unique_id", c(enzyme_name, measure_type, cond), remove = F)

```

Next I need to decide which landscapes are adaptive. These are listed below:

```{r}
adaptive_trajectories = c("DHFR_ki_trajg", 
                          "DHFR_ki_trajr",
                          "MPH_catact_ZnPTM",
                          "NfsA_ec50_2039",
                          "NfsA_ec50_3637",
                          "OXA-48_ic50_CAZtraj1",
                          "OXA-48_ic50_CAZtraj2",
                          "OXA-48_ic50_CAZtraj3",
                          "PTE_catact_2NH",
                          "TEM_MIC_weinreich",
                          "DHFR_ic75_palmer")

adaptive_traj = all_traj %>% filter(unique_id %in% adaptive_trajectories)
```
Which genotypes in the adaptive landscapes for the favored trajectory are POSITIVELY epistatic and epistatic in general 

Note: some trajectories don't go to the last variant, so we explore epistasis of all other genotypes which may go beyond last variant

```{r}
adaptive_traj_favored = adaptive_traj %>% filter(mutations > 1 & likely) %>% pull(avg)

sum(adaptive_traj_favored > log10(1.5)) / length(adaptive_traj_favored)

sum(adaptive_traj_favored > log10(1.5) | adaptive_traj_favored < log10(1/1.5)) / length(adaptive_traj_favored)
```
How many positive epistatic vs all epistatic genotypes vs all genotypes encountered in these landscapes?

```{r}
sum(adaptive_traj_favored > log10(1.5))
sum(adaptive_traj_favored > log10(1.5) | adaptive_traj_favored < log10(1/1.5))
length(adaptive_traj_favored)
```

Which genotypes in the non-adaptive landscapes for the favored trajectory are NEGATIVELY epistatic and epistatic in general

```{r}
`%notin%` <- Negate(`%in%`)

non_adaptive_traj_favored = all_traj %>% filter(unique_id %notin% adaptive_trajectories & mutations > 1 & !likely) %>% pull(avg)

sum(non_adaptive_traj_favored < log10(1/1.5))
sum(non_adaptive_traj_favored > log10(1.5) | non_adaptive_traj_favored < log10(1/1.5))
length(non_adaptive_traj_favored)

sum(non_adaptive_traj_favored < log10(1/1.5)) / length(non_adaptive_traj_favored)

sum(non_adaptive_traj_favored > log10(1.5) | non_adaptive_traj_favored < log10(1/1.5)) / length(non_adaptive_traj_favored)


```
### Prediction of relevant trajectories


```{r,message=F}
adaptive_traj_fave = adaptive_traj %>% filter(likely)

###

plotting_d = tibble()
dummy2 = data.frame()

for(i in 1:length(adaptive_trajectories)) {
  
  suffix = tail(str_split(adaptive_trajectories[i], "_")[[1]], 1)
  
  file = paste0("pred_df_", suffix, "_", adaptive_trajectories[i], ".csv")
  
  d = read_csv(paste0(adaptive_trajectories[i], "/", file))
  
  genos = str_replace_all(adaptive_traj_fave[which(adaptive_traj_fave$unique_id %in% adaptive_trajectories[i]),]$genotype, "x", "1")
  
  genos = c(str_replace(genos[1], "1", "0"), genos)
  
  dummy2 = rbind(dummy2, data.frame(trajectory = adaptive_trajectories[i], Z = d[which(d$numbers == tail(genos, 1)),]$`observed effect`))
  
  others = c()
  for(j in 1:(length(genos) - 2)) {
    others = c(others, colnames(d)[which(colnames(d) == "mutations") + j]) ## Get all steps before final step of evaluated genotype
  }
  
  plotting_d = rbind(plotting_d, d[which(d$numbers %in% genos),] %>%
    pivot_longer(cols = c(`observed effect`,
                          `epistatic effect`,
                          `WT effect`,
                          others)) %>% ## add those steps into line plots
    select(c(mutations, name, value)) %>%
    mutate(trajectory = adaptive_trajectories[i]))

}
```

Next we plot all of those

```{r}
ggplot(plotting_d, aes(x = mutations, y = value, color = name)) +
  geom_line(lwd = 2) +
  facet_wrap(~ trajectory) +
  geom_hline(data = dummy2, aes(yintercept = Z)) +
  geom_hline(data = dummy2, aes(yintercept = Z + log10(1.5)), lty = 2) +
  geom_hline(data = dummy2, aes(yintercept = Z - log10(1.5)), lty = 2) +
  geom_hline(data = dummy2, aes(yintercept = Z + log10(10)), lty = 2, color = "grey") +
  geom_hline(data = dummy2, aes(yintercept = Z - log10(10)), lty = 2, color = "grey") +
  theme_classic()
```


### Ruggedness plots

I can make a ruggedness plot for each adaptive landscape, where deviation from 0 implies epistatic contribution of that genotype

```{r}
adaptive_traj %>% 
  filter(mutations > 1 & likely) %>%
  ggplot(aes(x = mutations, y = avg)) +
  geom_line() +
  geom_text_repel(aes(label = genotype), force = 1.5, direction = "y", box.padding = 0, segment.size = 0.2, size = 2.5) +
  geom_hline(yintercept = log10(1.5), lty = 2) +
  geom_hline(yintercept = log10(1/1.5), lty = 2) +
  geom_hline(yintercept = 0) +
  facet_wrap(~ unique_id) +
  theme_classic()
```
What if we compare it to the mean at that combination or position as well, not just assumed additivity (0 +/- log10(1.5))?

```{r}
higher_means = higher_df %>%
  unite("partial_id", c(Enzyme, Measurement, Condition), remove = F) %>%
  filter(partial_id %in% adaptive_trajectories) %>% ## use partial ID to only pick up the adaptive trajectories
  group_by(unique_id) %>%
  mutate(avg = mean(avg)) %>% ## Is arithmetic mean OK here?
  ungroup() %>%
  distinct(unique_id, .keep_all = T) ## Remove unique_id replicates

adaptive_means = higher_means %>% arrange(partial_id, pos) %>% pull(avg)

adaptive_traj = adaptive_traj %>% arrange(unique_id, pos) %>% mutate(means = adaptive_means)

adaptive_traj %>%
  filter(likely) %>%
  mutate(wt_bg = avg) %>%
  pivot_longer(c(wt_bg, means)) %>%
  ggplot(aes(x = mutations, y = value, color = name)) +
  geom_line() +
  geom_text_repel(aes(label = genotype), force = 1.5, direction = "y", box.padding = 0, segment.size = 0.2, size = 2.5) +
  geom_hline(yintercept = log10(1.5), lty = 2) +
  geom_hline(yintercept = log10(1/1.5), lty = 2) +
  geom_hline(yintercept = 0) +
  facet_wrap(~ unique_id) +
  theme_classic()
  
```
Which one of the genotypes seen above are the outliers?

```{r}
adaptive_traj %>%
  mutate(outlier = abs(means - avg) > log10(1.5))
```


What % of adaptive landscape genotypes are outliers from the mean?
What % of adaptive accessible trajectory genotypes are outliers from the mean?
What % of adaptive less accessible trajectory genotypes are outliers from the mean?


```{r}
adaptive_traj_final = adaptive_traj %>%
  mutate(outlier = abs(means - avg) > log10(1.5))

length(adaptive_traj_final$outlier)
sum(adaptive_traj_final$outlier)
sum(adaptive_traj_final$outlier) / length(adaptive_traj_final$outlier)

length(filter(adaptive_traj_final, likely) %>% pull(outlier))
sum(filter(adaptive_traj_final, likely) %>% pull(outlier))
sum(filter(adaptive_traj_final, likely) %>% pull(outlier)) / length(filter(adaptive_traj_final, likely) %>% pull(outlier))

length(filter(adaptive_traj_final, !likely) %>% pull(outlier))
sum(filter(adaptive_traj_final, !likely) %>% pull(outlier))
sum(filter(adaptive_traj_final, !likely) %>% pull(outlier)) / length(filter(adaptive_traj_final, !likely) %>% pull(outlier))
```